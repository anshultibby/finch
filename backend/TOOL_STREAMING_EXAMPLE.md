# Tool Streaming System

## Overview

Tools can optionally stream progress updates during execution using `ToolStreamHandler`. This allows long-running tools to provide real-time feedback to users.

## Architecture

```
Tool ‚Üí ToolContext.stream_handler ‚Üí ToolStreamHandler ‚Üí Callback ‚Üí SSE/Logs/Storage
```

**Key Principles:**
- **Optional**: Tools work fine without streaming
- **Flexible**: Tools emit any type of event they want
- **Decoupled**: Stream handling is separate from tool logic

## Basic Example

```python
from modules.tools import tool, ToolContext

@tool(
    description="Analyze large dataset with progress updates",
    category="analysis"
)
async def analyze_dataset(
    *,
    context: ToolContext,
    data: List[Dict]
) -> Dict[str, Any]:
    """
    Example tool that streams progress
    """
    # Check if streaming is available
    if context.stream_handler:
        await context.stream_handler.emit_progress(0, "Starting analysis...")
    
    results = []
    total = len(data)
    
    for i, item in enumerate(data):
        # Do processing
        result = process_item(item)
        results.append(result)
        
        # Emit progress
        if context.stream_handler:
            progress = int((i + 1) / total * 100)
            await context.stream_handler.emit_progress(
                progress, 
                f"Processed {i+1}/{total} items"
            )
    
    if context.stream_handler:
        await context.stream_handler.emit_progress(100, "Analysis complete!")
    
    return {
        "success": True,
        "data": results,
        "total_processed": len(results)
    }
```

## Stream Handler API

###  emit_progress(percent, message)
```python
await context.stream_handler.emit_progress(50, "Halfway done")
# Emits: {"type": "progress", "percent": 50, "message": "Halfway done"}
```

### emit_log(level, message)
```python
await context.stream_handler.emit_log("info", "Fetching data from API")
await context.stream_handler.emit_log("warning", "Rate limit approaching")
await context.stream_handler.emit_log("error", "Failed to connect")
```

### emit_status(status, message)
```python
await context.stream_handler.emit_status("fetching", "Getting portfolio data")
await context.stream_handler.emit_status("processing", "Calculating returns")
await context.stream_handler.emit_status("complete", "Done!")
```

### emit_partial_result(data)
```python
# For tools that can return results incrementally
for batch in process_in_batches(data):
    await context.stream_handler.emit_partial_result(batch)
```

### emit(event_type, data)
```python
# Custom events
await context.stream_handler.emit("custom_metric", {
    "metric_name": "accuracy",
    "value": 0.95
})
```

## Using ToolStreamHandler

### 1. Console Logging (for development)

```python
from modules.tools import ToolStreamHandlerBuilder, ToolRunner

# Create logging handler
stream_handler = ToolStreamHandlerBuilder.create_logging_handler()

# Execute tool with streaming
runner = ToolRunner()
result = await runner.execute(
    tool_name="analyze_dataset",
    arguments={"data": big_data},
    session_id="user123",
    stream_handler=stream_handler
)

# Console output:
# üìä Progress: 0% - Starting analysis...
# üìä Progress: 25% - Processed 250/1000 items
# üìä Progress: 50% - Processed 500/1000 items
# üìä Progress: 100% - Analysis complete!
```

### 2. SSE Streaming (for frontend)

```python
async def execute_tool_with_sse(tool_name, arguments, session_id):
    """Execute tool and stream events to frontend"""
    
    async def sse_callback(event: Dict[str, Any]):
        # Convert tool event to SSE event
        from models.sse import SSEEvent
        yield SSEEvent(
            event=f"tool_{event['type']}",
            data=event
        )
    
    stream_handler = ToolStreamHandler(callback=sse_callback)
    
    result = await tool_runner.execute(
        tool_name=tool_name,
        arguments=arguments,
        session_id=session_id,
        stream_handler=stream_handler
    )
    
    return result
```

### 3. Storage (for testing)

```python
# Store events for later inspection
stream_handler = ToolStreamHandlerBuilder.create_storage_handler()

result = await tool_runner.execute(
    tool_name="analyze_dataset",
    arguments={"data": test_data},
    stream_handler=stream_handler
)

# Get all events
events = stream_handler.get_events()
assert events[0]["type"] == "progress"
assert events[-1]["percent"] == 100
```

## Real-World Examples

### Portfolio Analysis with Progress

```python
@tool(description="Analyze portfolio with detailed progress")
async def analyze_portfolio_risk(
    *,
    context: ToolContext,
    tickers: List[str]
) -> Dict[str, Any]:
    if context.stream_handler:
        await context.stream_handler.emit_status("initializing", "Loading portfolio data")
    
    portfolio = await fetch_portfolio(tickers)
    
    # Fetch historical data with progress
    historical_data = {}
    for i, ticker in enumerate(tickers):
        if context.stream_handler:
            progress = int((i / len(tickers)) * 50)  # First 50% for data fetching
            await context.stream_handler.emit_progress(
                progress,
                f"Fetching {ticker} data..."
            )
        historical_data[ticker] = await fetch_historical(ticker)
    
    # Calculate risk metrics with progress
    if context.stream_handler:
        await context.stream_handler.emit_status("calculating", "Computing risk metrics")
    
    risk_metrics = calculate_var(historical_data)
    
    if context.stream_handler:
        await context.stream_handler.emit_progress(75, "Calculating correlations")
    
    correlations = calculate_correlations(historical_data)
    
    if context.stream_handler:
        await context.stream_handler.emit_progress(100, "Analysis complete")
    
    return {
        "success": True,
        "risk_metrics": risk_metrics,
        "correlations": correlations
    }
```

### Web Scraping with Logs

```python
@tool(description="Scrape financial data from multiple sources")
async def scrape_financial_data(
    *,
    context: ToolContext,
    urls: List[str]
) -> Dict[str, Any]:
    results = []
    
    for url in urls:
        if context.stream_handler:
            await context.stream_handler.emit_log("info", f"Scraping {url}")
        
        try:
            data = await scrape_url(url)
            results.append(data)
            
            if context.stream_handler:
                await context.stream_handler.emit_log("info", f"‚úì Successfully scraped {url}")
        
        except Exception as e:
            if context.stream_handler:
                await context.stream_handler.emit_log("error", f"‚úó Failed to scrape {url}: {e}")
    
    return {
        "success": True,
        "data": results,
        "scraped_count": len(results)
    }
```

## Integration with Agents

Agents can provide stream handlers to tools:

```python
class BaseAgent:
    async def run_tool_loop(self, ...):
        # Create stream handler that logs to console
        from modules.tools import ToolStreamHandlerBuilder
        stream_handler = ToolStreamHandlerBuilder.create_logging_handler()
        
        # Execute tool with streaming
        context = ToolContext(
            session_id=session_id,
            user_id=user_id,
            stream_handler=stream_handler
        )
        
        result = await tool_registry.execute_tool(
            tool_name=func_name,
            arguments=func_args,
            context=context
        )
```

## Best Practices

### 1. Check Before Emitting
Always check if stream_handler exists:
```python
if context.stream_handler:
    await context.stream_handler.emit_progress(50, "Halfway")
```

### 2. Don't Over-Stream
Emit at meaningful intervals (not every iteration):
```python
# ‚ùå Bad: Too many events
for i in range(10000):
    if context.stream_handler:
        await context.stream_handler.emit_progress(i / 10000 * 100)

# ‚úÖ Good: Reasonable intervals
for i in range(10000):
    if i % 100 == 0 and context.stream_handler:
        await context.stream_handler.emit_progress(i / 10000 * 100)
```

### 3. Use Appropriate Event Types
- `emit_progress`: For % completion
- `emit_status`: For current activity
- `emit_log`: For informational messages
- `emit_partial_result`: For incremental results

### 4. Handle Errors Gracefully
```python
try:
    if context.stream_handler:
        await context.stream_handler.emit_log("info", "Starting risky operation")
    
    result = risky_operation()
    
    if context.stream_handler:
        await context.stream_handler.emit_log("info", "Operation succeeded")
except Exception as e:
    if context.stream_handler:
        await context.stream_handler.emit_log("error", f"Operation failed: {e}")
    raise
```

## Performance Considerations

- Stream events are **async** (non-blocking)
- Tools without streaming have **zero overhead**
- Console logging adds ~1ms per event
- SSE streaming adds ~5ms per event
- Storage mode is fastest (~0.1ms per event)

## Future Enhancements

- [ ] Rate limiting for stream events
- [ ] Event buffering for high-frequency tools
- [ ] Compression for large partial results
- [ ] Websocket support for real-time updates
- [ ] Frontend progress bars/logs UI
- [ ] Tool execution telemetry and metrics

## Summary

‚úÖ **Optional** - Works with or without streaming  
‚úÖ **Flexible** - Emit any type of event  
‚úÖ **Decoupled** - Stream handling separate from tools  
‚úÖ **Type-safe** - Proper types throughout  
‚úÖ **Zero overhead** - Only when used  
‚úÖ **Easy to test** - Storage mode for testing  

Tools can now provide real-time feedback without breaking existing code!

